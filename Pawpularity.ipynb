{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pawpularity.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WXnRbES619q"
      },
      "source": [
        "# Pawpularity Contest\n",
        "\n",
        "Submissions are scored on the root mean squared error **RMSE**.\n",
        "\n",
        "Guides to use:\n",
        "*   Multi Input ==> https://www.kaggle.com/yaniv256/tensorflow-multi-input-pet-pawpularity-model\n",
        "*   Transfer Learning ==> https://tfhub.dev/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI1Ulp0uaNwE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, Input\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler, TensorBoard\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.losses import MeanSquaredError, MeanSquaredLogarithmicError\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import backend as K\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APthzcCHOc3a"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "import datetime, os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiyG-KmGEapG"
      },
      "source": [
        "tensorflow.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkCrCgY3aNwO"
      },
      "source": [
        "input = Input(shape=(300, 300, 3))\n",
        "x = Conv2D(filters=32, kernel_size=(5,5), activation='relu')(input)\n",
        "x = Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
        "x = MaxPool2D((2,2))(x)\n",
        "x = Conv2D(filters=32, kernel_size=(5,5), activation='relu')(x)\n",
        "x = Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
        "x = MaxPool2D((2,2))(x)\n",
        "x = Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
        "x = Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
        "x = MaxPool2D((2,2))(x)\n",
        "x = Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
        "x = Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
        "x = MaxPool2D((2,2))(x)\n",
        "x = Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
        "x = Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
        "x = MaxPool2D((2,2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(10, activation=\"relu\")(x)\n",
        "x = Dropout(0.2)(x)\n",
        "output = Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "model = Model(input, output)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSXrIG2fGJJk"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVN3OKFm0dFJ"
      },
      "source": [
        "cd /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwPAKC1AGikf"
      },
      "source": [
        "# !unzip petfinder-pawpularity-score.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEOY-L77aNwZ"
      },
      "source": [
        "df = pd.read_csv('./train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__RkZ4AgaNwa"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8OQD6KtaNwi"
      },
      "source": [
        "df['Id'] = df['Id'] + '.jpg';\n",
        "df['Id']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmovayz3aNwl"
      },
      "source": [
        "# For SGD we have to normalize data\n",
        "# df['Pawpularity'] = df['Pawpularity'] / df['Pawpularity'].max()\n",
        "df['Pawpularity']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Rf7taCaNwn"
      },
      "source": [
        "# You can see more informations here https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "\n",
        "# tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "#     featurewise_center=False, samplewise_center=False,\n",
        "#     featurewise_std_normalization=False, samplewise_std_normalization=False,\n",
        "#     zca_whitening=False, zca_epsilon=1e-06, rotation_range=0, width_shift_range=0.0,\n",
        "#     height_shift_range=0.0, brightness_range=None, shear_range=0.0, zoom_range=0.0,\n",
        "#     channel_shift_range=0.0, fill_mode='nearest', cval=0.0,\n",
        "#     horizontal_flip=False, vertical_flip=False, rescale=None,\n",
        "#     preprocessing_function=None, data_format=None, validation_split=0.0, dtype=None\n",
        "# )\n",
        "\n",
        "train_dataGen = ImageDataGenerator(\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    zoom_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    rotation_range = 10,\n",
        "    shear_range = 10/180 * math.pi\n",
        ")\n",
        "\n",
        "# flow_from_dataframe(\n",
        "#     dataframe, directory=None, x_col='filename', y_col='class',\n",
        "#     weight_col=None, target_size=(256, 256), color_mode='rgb',\n",
        "#     classes=None, class_mode='categorical', batch_size=32, shuffle=True,\n",
        "#     seed=None, save_to_dir=None, save_prefix='',\n",
        "#     save_format='png', subset=None, interpolation='nearest',\n",
        "#     validate_filenames=True, **kwargs\n",
        "# )\n",
        "\n",
        "# target_size   tuple of integers (height, width), default: (256, 256). The dimensions to which all images found will be resized.\n",
        "# class_mode    one of \"binary\", \"categorical\", \"input\", \"multi_output\", \"raw\", sparse\" or None. \"sparse\": 1D numpy array of integer labels\n",
        "\n",
        "# TODO: We will need to pass the data as array of strings in order to use sparse!!!!\n",
        "\n",
        "train_gen = train_dataGen.flow_from_dataframe(\n",
        "    dataframe=df,\n",
        "    directory='./train',\n",
        "    x_col='Id',\n",
        "    y_col='Pawpularity',\n",
        "    target_size=(300, 300), \n",
        "    color_mode='rgb',\n",
        "    class_mode='raw',\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "def scheduler(epoch, learning_rate):\n",
        "  if epoch < 10:\n",
        "    return learning_rate\n",
        "  elif epoch == 10:\n",
        "    return learning_rate * tensorflow.math.exp(-0.1)\n",
        "  elif epoch == 20 :\n",
        "    return learning_rate * tensorflow.math.exp(-0.2)\n",
        "  elif epoch > 30 :\n",
        "    return learning_rate * tensorflow.math.exp(-0.2)\n",
        "\n",
        "learning_scheduler = LearningRateScheduler(scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsj6z7zS6Z8h"
      },
      "source": [
        "Despite the widespread popularity of Adam, recent research papers have noted that it can fail to converge to an optimal solution under specific settings. The paper Improving Generalization Performance by Switching from Adam to SGD demonstrates that adaptive optimization techniques such as Adam generalize poorly compared to SGD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wn7oauu7C28"
      },
      "source": [
        "# Settings\n",
        "adam_lr =  0.002#@param {type:\"slider\", min:0.0001, max:0.01, step:0.0001}\n",
        "sgd_lr =  0.01#@param {type:\"slider\", min:0.001, max:0.09, step:0.001}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLLrvXr-SciL"
      },
      "source": [
        "# tf.keras.optimizers.Adam(\n",
        "#     learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
        "#     name='Adam', **kwargs\n",
        "# )\n",
        "\n",
        "# tf.keras.optimizers.SGD(\n",
        "#     learning_rate=0.01, momentum=0.0, nesterov=False, name=\"SGD\", **kwargs\n",
        "# )\n",
        "\n",
        "# Lets tweak learning rate to see rate of conversion\n",
        "adam = Adam(learning_rate = adam_lr);\n",
        "sgd = SGD(learning_rate = sgd_lr);\n",
        "mse_loss = MeanSquaredError();\n",
        "msle_loss  = MeanSquaredLogarithmicError ();\n",
        "rmse = RootMeanSquaredError(name='rmse');\n",
        "\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.today().strftime('%Y-%m-%d-%H:%M'))\n",
        "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='rmse', patience=3, verbose=1, factor=0.75, min_lr=0.00001);\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"rmse\",\n",
        "    min_delta=0.05,\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    mode=\"min\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=False,\n",
        ");\n",
        "\n",
        "model.compile(loss=mse_loss, optimizer=adam, metrics=['mae',rmse]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZcPtCMJ7G6Z"
      },
      "source": [
        "epochs =  30#@param {type:\"slider\", min:10, max:300, step:10}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaOXqGUKaNwq"
      },
      "source": [
        "model.fit(train_gen, epochs=epochs, verbose=1, callbacks=[tensorboard_callback, reduce_lr, early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfX9_rCYaNws"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZmBYs_zxuZR8"
      },
      "source": [
        "model.save( 'my_model' + datetime.datetime.today().strftime('%Y-%m-%d-%H:%M') )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jADpYTse8T8R"
      },
      "source": [
        "For each Id in the test set, you must predict a probability for the target variable, Pawpularity. The file should contain a header and have the following format:\n",
        "\n",
        "Id, Pawpularity \\\n",
        "0008dbfb52aa1dc6ee51ee02adf13537, 99.24 \\\n",
        "0014a7b528f1682f0cf3b73a991c17a0, 61.71 \\\n",
        "0019c1388dfcd30ac8b112fb4250c251, 6.23 \\\n",
        "00307b779c82716b240a24f028b0031b, 9.43 \\\n",
        "00320c6dd5b4223c62a9670110d47911, 70.89 \\\n",
        "etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwzrp0bT8Uvm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}